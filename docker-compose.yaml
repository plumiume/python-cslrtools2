services:
  # CUDA 12.8 (メイン開発環境)
  pytorch-cu128:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - UV_PROJECT_ENVIRONMENT=/home/ubuntu/.venv
    volumes:
      - .:/workspace:cached
      - venv-cu128:/home/ubuntu/.venv
    working_dir: /workspace
    command: tail -f /dev/null

  # CUDA 12.6 (後方互換性検証)
  pytorch-cu126:
    build:
      context: .
      dockerfile: Dockerfile.cu126
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - UV_PROJECT_ENVIRONMENT=/home/ubuntu/.venv
    volumes:
      - .:/workspace:cached
      - venv-cu126:/home/ubuntu/.venv
    working_dir: /workspace
    command: tail -f /dev/null

  # CUDA 13.0 (最新CUDA検証)
  pytorch-cu130:
    build:
      context: .
      dockerfile: Dockerfile.cu130
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - UV_PROJECT_ENVIRONMENT=/home/ubuntu/.venv
    volumes:
      - .:/workspace:cached
      - venv-cu130:/home/ubuntu/.venv
    working_dir: /workspace
    command: tail -f /dev/null

  # CPU版 (CI/CD用)
  pytorch-cpu:
    build:
      context: .
      dockerfile: Dockerfile.cpu
    environment:
      - UV_PROJECT_ENVIRONMENT=/home/ubuntu/.venv
    volumes:
      - .:/workspace:cached
      - venv-cpu:/home/ubuntu/.venv
    working_dir: /workspace
    command: tail -f /dev/null

  # PyTorch 2.3.0 (最小バージョン検証 - uv init方式)
  pytorch-2.3-cu128:
    build:
      context: .
      dockerfile: Dockerfile.torch23
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - .:/workspace:ro
    working_dir: /workspace
    command: tail -f /dev/null

volumes:
  venv-cu128:
  venv-cu126:
  venv-cu130:
  venv-cpu:
