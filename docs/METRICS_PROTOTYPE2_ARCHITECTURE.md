# metrics_prototype2/ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è§£èª¬

**ä½œæˆæ—¥**: 2025å¹´12æœˆ2æ—¥  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: PROTOTYPE v2 - SLDatasetçµ±åˆç‰ˆ  
**å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: metrics_prototype/ (å‰Šé™¤æ¸ˆã¿)

---

## ğŸ“‹ æ¦‚è¦

`metrics_prototype2/` ã¯ã€ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å“è³ªè©•ä¾¡ã®ãŸã‚ã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹ã®
ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ç¬¬2ç‰ˆã§ã™ã€‚v1ã‹ã‚‰ã®ä¸»è¦ãªæ”¹å–„ç‚¹ã¯ã€
**cslrtools2.sldataset ã¨ã®å®Œå…¨ãªçµ±åˆ**ã§ã™ã€‚

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³å±¥æ­´

**v2.1 (2025-12-02)**: importlib.metadataçµ±åˆã€Calculator ãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ 

| é …ç›® | v1 | v2.0 | v2.1 (Latest) |
|------|----|----|----|
| ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç™»éŒ² | ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ | ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ | importlib.metadata |
| ãƒ¦ãƒ¼ã‚¶ãƒ¼API | ç›´æ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ– | create_metric() | MetricCalculator |
| ãƒ¡ãƒˆãƒªã‚¯ã‚¹éšå±¤ | Metric | Metric | Metric â†’ LandmarkMetric |
| zarråˆ¤å®š | N/A | .zarræ‹¡å¼µå­ | .zgroup/.zarray ãƒã‚§ãƒƒã‚¯ |
| ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ | æ‰‹å‹•zarrèµ°æŸ» | `SLDataset.from_zarr()` | åŒå·¦ |
| é…å»¶èª­ã¿è¾¼ã¿ | ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£… | zarr.Arrayå‚ç…§æ´»ç”¨ | åŒå·¦ |
| ãƒ‡ãƒ¼ã‚¿å¤‰æ› | ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ | `to_numpy_landmarks()` | `np.asarray()` + `__array__` |
| ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ | ãªã— | `utils.py` æ–°è¨­ | åŒå·¦ |
| ã‚³ãƒ¼ãƒ‰é‡ | åŸºæº– | 30-40%å‰Šæ¸› | 40-50%å‰Šæ¸› |
| å‹å®‰å…¨æ€§ | åŸºæœ¬ | å¼·åŒ–ï¼ˆDTypeLikeç­‰ï¼‰ | åŒå·¦ |

---

## ğŸ—ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
metrics_prototype2/
â”œâ”€â”€ __init__.py           # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€APIå…¬é–‹
â”œâ”€â”€ base.py              # æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ (Metric ABC)
â”œâ”€â”€ loader.py            # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç™»éŒ²ãƒ»æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€â”€ utils.py             # NEW: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ demo.py              # ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆSLDatasetçµ±åˆç‰ˆï¼‰
â”œâ”€â”€ README.md            # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—èª¬æ˜
â””â”€â”€ plugins/             # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ completeness.py  # Phase 1: NaNç‡è¨ˆç®—
    â”œâ”€â”€ temporal.py      # Phase 2: æ™‚é–“çš„ä¸€è²«æ€§
    â””â”€â”€ anatomical.py    # Phase 3: éª¨æ ¼åˆ¶ç´„
```

---

## ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    subgraph "Entry Point"
        CLI[CLI / demo.py]
    end
    
    subgraph "Core System"
        Init[__init__.py<br/>API Export]
        Loader[loader.py<br/>Plugin Registry]
        Base[base.py<br/>Metric ABC]
        Utils[utils.py<br/>NEW: Helpers]
    end
    
    subgraph "Plugins"
        P1[completeness.py<br/>NaNRateMetric]
        P2[temporal.py<br/>TemporalConsistencyMetric]
        P3[anatomical.py<br/>AnatomicalConstraintMetric]
    end
    
    subgraph "Data Layer - SLDataset Integration"
        SLD[SLDataset.from_zarr]
        Item[SLDatasetItem<br/>with zarr.Array refs]
        Utils2[np.asarray + __array__<br/>categorize_landmarks<br/>combine_landmarks]
    end
    
    subgraph "Storage"
        Zarr[(Zarr Dataset)]
    end
    
    CLI -->|1. create calculator| Loader
    CLI -->|2. add_metric| Loader
    Loader -->|3. load from| EntryPoints[importlib.metadata<br/>Entry Points]
    Loader -->|4. instantiate| Base
    Base -.implements.-> P1
    Base -.implements.-> P2
    Base -.implements.-> P3
    
    CLI -->|5. load data| SLD
    Zarr -->|read| SLD
    SLD -->|6. return| Item
    Item -->|7. convert| Utils2
    Utils2 -->|8. NumPy arrays| Utils
    
    CLI -->|9. calculate| P1
    CLI -->|9. calculate| P2
    CLI -->|9. calculate| P3
    
    P1 -->|10. return| Result[MetricResult]
    P2 -->|10. return| Result
    P3 -->|10. return| Result
    
    style CLI fill:#e1f5ff
    style Base fill:#fff4e1
    style Utils fill:#fff9c4
    style Utils2 fill:#fff9c4
    style P1 fill:#e8f5e9
    style P2 fill:#e8f5e9
    style P3 fill:#e8f5e9
    style SLD fill:#f3e5f5
    style Item fill:#f3e5f5
    style Zarr fill:#f3e5f5
    style Result fill:#ffebee
```

---

## ğŸ”‘ v2.1 ä¸»è¦å¤‰æ›´ç‚¹

### 1. importlib.metadata çµ±åˆ

**å¤‰æ›´å‰ (v2.0)**: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸãƒ¬ã‚¸ã‚¹ãƒˆãƒª
```python
_SIMULATED_PLUGINS = {}
register_metric("completeness.nan_rate", NaNRateMetric, {})
```

**å¤‰æ›´å¾Œ (v2.1)**: Entry PointsçµŒç”±
```python
# pyproject.toml
[project.entry-points."cslrtools2.sldataset.metrics"]
"completeness.nan_rate" = "package:NaNRateMetric"

# Python code
eps = entry_points(group="cslrtools2.sldataset.metrics")
```

### 2. Calculator ãƒ‘ã‚¿ãƒ¼ãƒ³

**å¤‰æ›´å‰ (v2.0)**: ç›´æ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
```python
metric = create_metric("completeness.nan_rate")
result = metric.calculate(data)
```

**å¤‰æ›´å¾Œ (v2.1)**: Calculatorç®¡ç†
```python
calculator = MetricCalculator()
calculator.add_metric("completeness.nan_rate")
results = calculator.calculate(data)  # å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¸€æ‹¬å®Ÿè¡Œ
```

### 3. ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®ç°¡ç´ åŒ–

**å¤‰æ›´å‰ (v2.0)**: å°‚ç”¨é–¢æ•°
```python
from metrics_prototype2.utils import to_numpy_landmarks
landmarks_np = to_numpy_landmarks(item.landmarks)
```

**å¤‰æ›´å¾Œ (v2.1)**: æ¨™æº–NumPyé–¢æ•°
```python
import numpy as np
landmarks_np = {k: np.asarray(v) for k, v in item.landmarks.items()}
```

### 4. zarråˆ¤å®šã®æ”¹å–„

**å¤‰æ›´å‰ (v2.0)**: æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯ï¼ˆä¸æ­£ç¢ºï¼‰
```python
if str(dataset_path).endswith(".zarr"):
    root = zarr.open_group(dataset_path, mode="r")
```

**å¤‰æ›´å¾Œ (v2.1)**: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
```python
zarr_json_path = dataset_path / ".zgroup"
if not zarr_json_path.exists():
    zarr_json_path = dataset_path / ".zarray"

if zarr_json_path.exists():
    root = zarr.open_group(str(dataset_path), mode="r")
else:
    raise ValueError("Not a valid zarr dataset")
```

---

## ğŸ¯ ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

### 1. base.py - æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ (v2.1: éšå±¤åŒ–)

**å½¹å‰²**: ã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå®Ÿè£…ã™ã¹ãã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®šç¾©

```mermaid
classDiagram
    class Metric {
        <<abstract>>
        +calculate(data: NDArray, **kwargs) MetricResult
        +validate_inputs(data: NDArray) bool
        +get_description() str
    }
    
    class MetricResult {
        <<TypedDict>>
        +metric_name: str
        +values: Mapping[str, float]
        +metadata: Mapping[str, Any]
    }
    
    class NaNRateMetric {
        +calculate(data, **kwargs) MetricResult
        +validate_inputs(data) bool
        +get_description() str
    }
    
    class TemporalConsistencyMetric {
        +calculate(data, **kwargs) MetricResult
        +validate_inputs(data) bool
        +get_description() str
    }
    
    class AnatomicalConstraintMetric {
        +calculate(data, bone_pairs, **kwargs) MetricResult
        +validate_inputs(data) bool
        +get_description() str
    }
    
    Metric <|-- LandmarkMetric
    Metric <|-- RGBMetric : Future
    Metric <|-- ConnectionMetric : Future
    LandmarkMetric <|-- NaNRateMetric
    LandmarkMetric <|-- TemporalConsistencyMetric
    LandmarkMetric <|-- AnatomicalConstraintMetric
    Metric ..> MetricResult : returns
```

**v2.1 ã‚¯ãƒ©ã‚¹éšå±¤**:
- `Metric`: å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ±ç”¨ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
- `LandmarkMetric`: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å“è³ªè©•ä¾¡å°‚ç”¨ï¼ˆ`NDArray[np.float32]`å…¥åŠ›ï¼‰
- (Future) `RGBMetric`, `ConnectionMetric`, `TargetMetric`: å°†æ¥ã®æ‹¡å¼µ

**ä¸»è¦ãªè¨­è¨ˆåŸå‰‡**:
- **ã‚¨ãƒ³ã‚¸ãƒ³éä¾å­˜**: MediaPipe, OpenPoseç­‰ã®ç‰¹å®šã‚¨ãƒ³ã‚¸ãƒ³ã«ä¾å­˜ã—ãªã„
- **Ground Truthä¸è¦**: å‚ç…§ãƒ‡ãƒ¼ã‚¿ãªã—ã§è©•ä¾¡å¯èƒ½
- **å‹å®‰å…¨**: PEP 695ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ã¨Pyright strictæº–æ‹ 

**å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼**:
```python
data: NDArray[np.float32]  # shape: (frames, keypoints, coordinates)
# ä¾‹: (300, 33, 3) = 300ãƒ•ãƒ¬ãƒ¼ãƒ ã€33ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã€xyzåº§æ¨™
```

---

### 2. loader.py - ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  (v2.1: importlib.metadataçµ±åˆ)

**å½¹å‰²**: å¤–éƒ¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å‹•çš„æ¤œå‡ºã¨Calculatorãƒ‘ã‚¿ãƒ¼ãƒ³æä¾›

```mermaid
sequenceDiagram
    participant User
    participant Calculator
    participant Loader
    participant EntryPoints
    participant MetricClass
    
    User->>Calculator: new MetricCalculator()
    User->>Calculator: add_metric("completeness.nan_rate")
    Calculator->>Loader: create_metric(name)
    Loader->>EntryPoints: entry_points(group="cslrtools2.sldataset.metrics")
    EntryPoints-->>Loader: list of entry points
    Loader->>MetricClass: load() and instantiate
    MetricClass-->>Calculator: metric instance
    
    User->>Calculator: calculate(data)
    Calculator->>MetricClass: calculate(data)
    MetricClass-->>Calculator: MetricResult
    Calculator-->>User: dict[name, MetricResult]
```

**v2.1 Calculator Pattern**:
```python
from metrics_prototype2 import MetricCalculator
import numpy as np

# 1. Create calculator
calculator = MetricCalculator()

# 2. Register metrics
calculator.add_metric("completeness.nan_rate")
calculator.add_metric("temporal.smoothness", window=5)

# 3. Calculate all at once
landmarks_np = {k: np.asarray(v) for k, v in item.landmarks.items()}
results = calculator.calculate(landmarks_np["mediapipe.pose"])

# 4. Access results
print(results["completeness.nan_rate"]["value"])  # 0.05
```

**å¤–éƒ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ç™»éŒ² (pyproject.toml)**:
```toml
[project.entry-points."cslrtools2.sldataset.metrics"]
"custom.my_metric" = "my_package.metrics:MyMetric"
```

**MetricInfoæ§‹é€ **:
```python
class MetricInfo(TypedDict):
    name: str                      # "completeness.nan_rate"
    category: str                  # "completeness"
    metric_name: str               # "nan_rate"
    metric_class: type[Metric]     # NaNRateMetric
    default_params: Mapping[str, Any]  # {}
```

---

### 3. utils.py - ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â­ NEW

**å½¹å‰²**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ»åˆ†é¡

```mermaid
graph LR
    subgraph "Input: SLDatasetItem"
        I1[landmarks: Mapping<br/>zarr.Array refs]
    end
    
    subgraph "utils.py Functions"
        F1[to_numpy_landmarks]
        F2[categorize_landmarks]
        F3[combine_landmarks]
    end
    
    subgraph "Output"
        O1[NumPy arrays<br/>dict[str, ndarray]]
        O2[Categories<br/>dict[str, list]]
        O3[Combined array<br/>ndarray]
    end
    
    I1 -->|convert| F1
    F1 --> O1
    O1 -->|classify| F2
    F2 --> O2
    O1 -->|merge| F3
    F3 --> O3
    
    style I1 fill:#f3e5f5
    style F1 fill:#fff9c4
    style F2 fill:#fff9c4
    style F3 fill:#fff9c4
    style O1 fill:#e8f5e9
    style O2 fill:#e8f5e9
    style O3 fill:#e8f5e9
```

#### 3.1 np.asarray() + `__array__` ãƒ—ãƒ­ãƒˆã‚³ãƒ« (v2.1 å¤‰æ›´)

**ç›®çš„**: zarr.Arrayå‚ç…§ã‚’NumPyé…åˆ—ã«å¤‰æ›ï¼ˆé…å»¶èª­ã¿è¾¼ã¿ã®å®Ÿè¡Œãƒã‚¤ãƒ³ãƒˆï¼‰

**v2.1 ã§ã¯ `to_numpy_landmarks()` ã‚’å‰Šé™¤ã—ã€æ¨™æº–çš„ãª `np.asarray()` ã‚’æ¨å¥¨**:

```python
import numpy as np
from cslrtools2.sldataset import SLDataset
import zarr

root = zarr.open_group("dataset.zarr", mode="r")
dataset = SLDataset.from_zarr(root)
item = dataset[0]  # zarr.Array references

# v2.1: ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ + np.asarray()
landmarks_np = {
    k: np.asarray(v, dtype=np.float32) 
    for k, v in item.landmarks.items()
}
# landmarks_np = {"mediapipe.pose": ndarray(300, 33, 3), ...}
```

**å¤‰æ›´ç†ç”±**:
- `zarr.Array` ã¯ `__array__()` ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’å®Ÿè£…æ¸ˆã¿
- å°‚ç”¨é–¢æ•°ã¯ä¸è¦ï¼ˆNumPyæ¨™æº–æ©Ÿèƒ½ã§ååˆ†ï¼‰
- ã‚³ãƒ¼ãƒ‰ç°¡æ½”åŒ–

#### 3.2 categorize_landmarks() (v2.1 ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ”¹å–„)

**ç›®çš„**: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚­ãƒ¼ã‚’ä½“ã®éƒ¨ä½ã”ã¨ã«åˆ†é¡

**v2.1 å¤‰æ›´ç‚¹**: `.` åˆ†å‰²ã®æœ€å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¤å®š

```python
def categorize_landmarks(landmark_keys: Iterable[str]) -> dict[str, list[str]]:
    """Categorize by suffix after last '.'
    
    Examples:
        "mediapipe.pose" -> "pose" -> Pose category
        "openpose.left_hand" -> "left_hand" -> Left Hand category
    """
    # v2.1: rsplit(".", 1)[-1] ã§åˆ¤å®š
    suffix = key.rsplit(".", 1)[-1].lower()
    if suffix in ("pose", "body"):
        categories["Pose"].append(key)
```

**åˆ©ç‚¹**: ã‚¨ãƒ³ã‚¸ãƒ³åï¼ˆmediapipe, openposeç­‰ï¼‰ã«éä¾å­˜

```python
def categorize_landmarks(
    landmark_keys: Iterable[str]
) -> dict[str, list[str]]:
    """Categorize landmark keys by body part.
    
    Recognizes:
        - Pose: Full body keypoints
        - Left Hand: Left hand keypoints
        - Right Hand: Right hand keypoints
        - Face: Facial landmarks
    """
```

**èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³**:
- **Pose**: `"pose"`, `"body"` ã‚’å«ã‚€
- **Left Hand**: `"left"` + `"hand"` ã‚’å«ã‚€
- **Right Hand**: `"right"` + `"hand"` ã‚’å«ã‚€
- **Face**: `"face"`, `"facial"` ã‚’å«ã‚€

**ä½¿ç”¨ä¾‹**:
```python
keys = ["mediapipe.pose", "mediapipe.left_hand", "mediapipe.right_hand"]
categories = categorize_landmarks(keys)
# {
#   "Pose": ["mediapipe.pose"],
#   "Left Hand": ["mediapipe.left_hand"],
#   "Right Hand": ["mediapipe.right_hand"]
# }
```

#### 3.3 combine_landmarks()

**ç›®çš„**: è¤‡æ•°ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯é…åˆ—ã‚’çµåˆï¼ˆä¾‹: ä¸¡æ‰‹ã€å…¨ä½“ï¼‰

```python
def combine_landmarks(
    landmarks: Mapping[str, np.ndarray],
    keys: list[str],
    axis: int = 1
) -> np.ndarray:
    """Combine multiple landmark arrays along specified axis.
    
    Args:
        landmarks: Mapping of landmark key to NumPy array
        keys: Keys to combine
        axis: Axis to concatenate along (default: 1 for keypoints)
    """
```

**ä½¿ç”¨ä¾‹**:
```python
# ä¸¡æ‰‹ã®çµåˆ
hands_keys = ["mediapipe.left_hand", "mediapipe.right_hand"]
hands_combined = combine_landmarks(landmarks_np, hands_keys, axis=1)
# shape: (300, 42, 3)  # 21 + 21 = 42 keypoints

# å…¨ä½“ã®çµåˆ
all_keys = list(landmarks_np.keys())
all_combined = combine_landmarks(landmarks_np, all_keys, axis=1)
# shape: (300, 543, 3)  # 33 + 21 + 21 + 468 = 543 keypoints
```

**è¨­è¨ˆåˆ¤æ–­**: ãªãœ `sldataset.utils` ã«å…¥ã‚Œãªã„ã®ã‹ï¼Ÿ

1. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹å›ºæœ‰ã®ãƒ­ã‚¸ãƒƒã‚¯**: ä½“éƒ¨ä½ã®åˆ†é¡ã¯ç”¨é€”ä¾å­˜
2. **æ‹¡å¼µæ€§**: å°†æ¥çš„ã«ç•°ãªã‚‹åˆ†é¡ã‚¹ã‚­ãƒ¼ãƒ ãŒå¿…è¦ã«ãªã‚‹å¯èƒ½æ€§
3. **è²¬ä»»åˆ†é›¢**: `sldataset` ã¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€`metrics` ã¯è©•ä¾¡å‡¦ç†

---

### 4. demo.py - SLDatasetçµ±åˆãƒ‡ãƒ¢

**å½¹å‰²**: v2ã®ä¸»è¦æ”¹å–„ç‚¹ã‚’å®Ÿè¨¼

#### v1 vs v2 æ¯”è¼ƒ

| æ©Ÿèƒ½ | v1å®Ÿè£… | v2å®Ÿè£… |
|------|--------|--------|
| ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ | æ‰‹å‹•zarrèµ°æŸ» | `SLDataset.from_zarr()` |
| é…å»¶è©•ä¾¡ | ã‚«ã‚¹ã‚¿ãƒ iterator | zarr.Arrayå‚ç…§ |
| ãƒ‡ãƒ¼ã‚¿å¤‰æ› | ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³å‡¦ç† | `np.asarray()` + `__array__` |
| zarråˆ¤å®š | N/A | `.zgroup`/`.zarray` ãƒã‚§ãƒƒã‚¯ |
| éƒ¨ä½åˆ†é¡ | ãªã— | `categorize_landmarks()` |
| çµåˆå‡¦ç† | æ‰‹å‹• | `combine_landmarks()` |

#### ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

```mermaid
flowchart TD
    Start([Start: demo.py])
    
    subgraph "1. Data Loading - SLDataset"
        ZarrCheck{.zgroup or<br/>.zarray exists?}
        Error[Raise ValueError:<br/>Not a valid zarr dataset]
        Open[zarr.open_group]
        Check{Nested<br/>structure?}
        Inner[Access inner group]
        Load[SLDataset.from_zarr]
    end
    
    Start --> ZarrCheck
    ZarrCheck -->|No| Error
    ZarrCheck -->|Yes| Open
    
    subgraph "3. Processing Mode"
        Mode{args.all?}
        Single[Process single sample]
        Batch[Process all samples]
    end
    
    subgraph "4. Metrics Calculation"
        Item[Get SLDatasetItem<br/>zarr.Array refs]
        Convert[np.asarray + __array__<br/>Lazy evaluation here]
        Cat[categorize_landmarks]
        
        subgraph "Per Category"
            M1[NaN Rate]
            M2[Temporal Consistency]
            M3[Anatomical Constraint]
        end
        
        Combine[combine_landmarks<br/>Hands, All]
    end
    
    subgraph "5. Output"
        Display[Print results]
        Save{args.output?}
        JSON[Save to JSON]
    end
    
    Open --> Check
    Check -->|Yes| Inner
    Check -->|No| Load
    Inner --> Load
    
    Load --> Mode
    Mode -->|False| Single
    Mode -->|True| Batch
    
    Single --> Item
    Batch --> Item
    
    Item --> Convert
    Convert --> Cat
    Cat --> M1
    Cat --> M2
    Cat --> M3
    Cat --> Combine
    
    Combine --> Display
    Display --> Save
    Save -->|Yes| JSON
    Save -->|No| End([End])
    JSON --> End
    
    style Start fill:#e1f5ff
    style Reg fill:#fff4e1
    style Load fill:#f3e5f5
    style Convert fill:#fff9c4
    style M1 fill:#e8f5e9
    style M2 fill:#e8f5e9
    style M3 fill:#e8f5e9
    style End fill:#ffebee
```

#### ä½¿ç”¨ä¾‹

```bash
# å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«
uv run python -m metrics_prototype2.demo \
    --dataset C:\path\to\dataset.zarr \
    --sample-idx 0

# å…¨ã‚µãƒ³ãƒ—ãƒ« + JSONå‡ºåŠ›
uv run python -m metrics_prototype2.demo \
    --dataset C:\path\to\dataset.zarr \
    --all \
    --output results.json
```

---

## ğŸ“Š å®Ÿè£…ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹

### Phase 1: Completeness (completeness.py)

```mermaid
graph LR
    Input[Input: landmarks<br/>shape: T, K, D]
    Check{Frame t has<br/>any NaN?}
    Count[Count frames<br/>with NaN]
    Rate[Calculate<br/>nan_rate]
    
    Input --> Check
    Check -->|Yes| Count
    Check -->|No| Count
    Count --> Rate
    
    style Input fill:#e3f2fd
    style Check fill:#fff9c4
    style Rate fill:#e8f5e9
```

**æ•°å¼**:
```
frame_has_nan[t] = âˆ¨_{k,d} isNaN(X[t, k, d])
nan_rate = (1/T) Î£_t frame_has_nan[t]
```

**è§£é‡ˆ**:
- `0.0` (0%): å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã€æ¬ æãªã—
- `0.2` (20%): 20%ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ¬ æã‚ã‚Šï¼ˆæ¨å¥¨é–¾å€¤ï¼‰
- `1.0` (100%): å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ¬ æã‚ã‚Šï¼ˆç„¡åŠ¹ï¼‰

---

### Phase 2: Temporal Consistency (temporal.py)

```mermaid
graph TD
    Input[Input: landmarks<br/>shape: T, K, D]
    
    subgraph "Velocity Calculation"
        V[velocity = X[t+1] - X[t]<br/>shape: T-1, K, D]
    end
    
    subgraph "Acceleration Calculation"
        A[acceleration = V[t+1] - V[t]<br/>shape: T-2, K, D]
    end
    
    subgraph "Statistics"
        S1[mean_velocity = mean|V|]
        S2[smoothness = std A]
    end
    
    Input --> V
    V --> A
    A --> S1
    A --> S2
    
    style Input fill:#e3f2fd
    style V fill:#fff9c4
    style A fill:#ffe0b2
    style S1 fill:#e8f5e9
    style S2 fill:#e8f5e9
```

**æ•°å¼**:
```
velocity[t] = X[t+1] - X[t]
acceleration[t] = velocity[t+1] - velocity[t]
smoothness = std(acceleration)
```

**è§£é‡ˆ**:
- **ä½ã„smoothness**: æ»‘ã‚‰ã‹ãªå‹•ãï¼ˆè‰¯å¥½ï¼‰
- **é«˜ã„smoothness**: ã‚¸ãƒƒã‚¿ãŒå¤šã„ï¼ˆè¦æ”¹å–„ï¼‰

**æœ€å°ãƒ•ãƒ¬ãƒ¼ãƒ æ•°**: 3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆåŠ é€Ÿåº¦è¨ˆç®—ã®ãŸã‚ï¼‰

---

### Phase 3: Anatomical Constraint (anatomical.py)

```mermaid
graph TD
    Input[Input: landmarks + bone_pairs<br/>shape: T, K, D]
    
    subgraph "Per Bone Pair i, j"
        B1[bone_vector = X[:, i] - X[:, j]]
        B2[bone_length = ||bone_vector||<br/>shape: T]
        B3[mean_length = mean bone_length]
        B4[std_length = std bone_length]
        B5[CV = std_length / mean_length]
    end
    
    subgraph "Summary Statistics"
        S1[mean_variation = mean CV]
        S2[std_variation = std CV]
    end
    
    Input --> B1
    B1 --> B2
    B2 --> B3
    B2 --> B4
    B3 --> B5
    B4 --> B5
    B5 --> S1
    B5 --> S2
    
    style Input fill:#e3f2fd
    style B2 fill:#fff9c4
    style B5 fill:#ffe0b2
    style S1 fill:#e8f5e9
    style S2 fill:#e8f5e9
```

**æ•°å¼**:
```
bone_length[t] = ||X[t, i] - X[t, j]||â‚‚
CV = std(bone_length) / mean(bone_length)
mean_variation = (1/N) Î£_bones CV
```

**MediaPipe Poseãƒœãƒ¼ãƒ³å®šç¾©** (12æœ¬):
- **Torso**: è‚©ã€è…°ã®æ¥ç¶š
- **Left Arm**: è‚©â†’è‚˜â†’æ‰‹é¦–
- **Right Arm**: è‚©â†’è‚˜â†’æ‰‹é¦–
- **Left Leg**: è…°â†’è†â†’è¶³é¦–
- **Right Leg**: è…°â†’è†â†’è¶³é¦–

**è§£é‡ˆ**:
- **ä½ã„mean_variation**: ä¸€è²«ã—ãŸéª¨æ ¼æ§‹é€ ï¼ˆè‰¯å¥½ï¼‰
- **é«˜ã„mean_variation**: ç‰©ç†çš„ã«ä¸è‡ªç„¶ãªå§¿å‹¢ï¼ˆè¦æ”¹å–„ï¼‰

---

## ğŸ”Œ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®æ‹¡å¼µ

### æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½åŠ æ–¹æ³•

```mermaid
sequenceDiagram
    participant Dev as é–‹ç™ºè€…
    participant File as new_metric.py
    participant Base as Metric ABC
    participant Reg as Registry
    participant Demo as demo.py
    
    Dev->>File: 1. Create plugin file
    File->>Base: 2. Inherit from Metric
    File->>File: 3. Implement calculate()
    File->>File: 4. Implement get_description()
    File->>File: 5. Define *_info tuple
    
    Dev->>File: 6. Register in pyproject.toml
    Note right of Dev: [project.entry-points]<br/>"cslrtools2.sldataset.metrics"<br/>"custom.my_metric" = "pkg:MyMetric"
    
    Dev->>Demo: 7. Run demo
    Demo->>Reg: 8. MetricCalculator.add_metric()
    Reg->>File: 9. Load via importlib.metadata
    Reg->>File: 10. Instantiate
    File-->>Demo: 11. Metric instance
    Demo->>File: 12. calculate()
    File-->>Demo: 13. MetricResult
```

### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```python
# metrics_prototype2/plugins/my_metric.py

from __future__ import annotations
from typing import Any
import numpy as np
from numpy.typing import NDArray
from metrics_prototype2.base import LandmarkMetric, MetricResult

class MyMetric(LandmarkMetric):
    """Brief description of your metric.
    
    v2.1: Inherits from LandmarkMetric for landmark-specific metrics.
    Use base Metric class for other metric types (RGB, Connection, etc.)
    
    Detailed explanation, mathematical formula, interpretation.
    """
    
    def calculate(
        self, data: NDArray[np.float32], **kwargs: Any
    ) -> MetricResult:
        """Calculate the metric.
        
        Args:
            data: Landmark array (T, K, D)
            **kwargs: Additional parameters
        
        Returns:
            MetricResult with values and metadata
        """
        self.validate_inputs(data)
        
        # Your calculation here
        value = np.mean(data)
        
        return MetricResult(
            metric_name="my_metric",
            values={"score": float(value)},
            metadata={"shape": data.shape},
        )
    
    def get_description(self) -> str:
        return "Description of what this metric measures"

# Plugin info
my_metric_info: tuple[type[MyMetric], dict[str, Any]] = (MyMetric, {})
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆæ§‹é€ 

```
tests/unit/metrics_prototype2/
â”œâ”€â”€ test_base.py              # Metric ABC
â”œâ”€â”€ test_loader.py            # Plugin registry
â”œâ”€â”€ test_utils.py             # Utility functions
â”œâ”€â”€ test_completeness.py      # NaN rate metric
â”œâ”€â”€ test_temporal.py          # Temporal consistency
â””â”€â”€ test_anatomical.py        # Anatomical constraint
```

### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ä¾‹

```python
# tests/unit/metrics_prototype2/test_completeness.py

import numpy as np
import pytest
from metrics_prototype2.plugins.completeness import NaNRateMetric

def test_nan_rate_no_missing():
    """å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿: nan_rate = 0.0"""
    metric = NaNRateMetric()
    data = np.random.rand(100, 33, 3).astype(np.float32)
    result = metric.calculate(data)
    assert result["values"]["nan_rate"] == 0.0

def test_nan_rate_partial_missing():
    """10ãƒ•ãƒ¬ãƒ¼ãƒ æ¬ æ: nan_rate = 0.1"""
    metric = NaNRateMetric()
    data = np.random.rand(100, 33, 3).astype(np.float32)
    data[10:20, :, :] = np.nan
    result = metric.calculate(data)
    assert result["values"]["nan_rate"] == 0.1

def test_nan_rate_all_missing():
    """å…¨ãƒ•ãƒ¬ãƒ¼ãƒ æ¬ æ: ValueError"""
    metric = NaNRateMetric()
    data = np.full((100, 33, 3), np.nan, dtype=np.float32)
    with pytest.raises(ValueError, match="All frames.*contain NaN"):
        metric.calculate(data)
```

---

## ğŸš€ æœ¬ç•ªçµ±åˆãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç§»è¡Œ âœ… å®Œäº†

- [x] `base.py` â†’ `src/cslrtools2/sldataset/metrics/base.py`
- [x] `loader.py` â†’ `src/cslrtools2/sldataset/metrics/loader.py`
- [x] `utils.py` â†’ `src/cslrtools2/sldataset/metrics/utils.py`

### Phase 2: ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç§»è¡Œ

```mermaid
graph LR
    subgraph "Prototype"
        P1[metrics_prototype2/<br/>plugins/completeness.py]
        P2[metrics_prototype2/<br/>plugins/temporal.py]
        P3[metrics_prototype2/<br/>plugins/anatomical.py]
    end
    
    subgraph "Production"
        R1[src/cslrtools2/<br/>sldataset/metrics/<br/>completeness.py]
        R2[src/cslrtools2/<br/>sldataset/metrics/<br/>temporal.py]
        R3[src/cslrtools2/<br/>sldataset/metrics/<br/>anatomical.py]
    end
    
    P1 -.migrate.-> R1
    P2 -.migrate.-> R2
    P3 -.migrate.-> R3
    
    style P1 fill:#fff9c4
    style P2 fill:#fff9c4
    style P3 fill:#fff9c4
    style R1 fill:#e8f5e9
    style R2 fill:#e8f5e9
    style R3 fill:#e8f5e9
```

### Phase 3: Entry Pointsè¨­å®š

```toml
# pyproject.toml
[project.entry-points."cslrtools2.sldataset.metrics"]
"completeness.nan_rate" = "cslrtools2.sldataset.metrics.completeness:nan_rate_info"
"temporal.consistency" = "cslrtools2.sldataset.metrics.temporal:temporal_consistency_info"
"anatomical.bone_length" = "cslrtools2.sldataset.metrics.anatomical:anatomical_constraint_info"
```

### Phase 4: CLIçµ±åˆ

```bash
# ç›®æ¨™ã‚³ãƒãƒ³ãƒ‰
sldataset calculate-metrics \
    --dataset path/to/dataset.zarr \
    --metrics completeness temporal anatomical \
    --output metrics_report.json
```

```python
# src/cslrtools2/sldataset/app/cli.py

@cli.command()
@click.option("--dataset", type=click.Path(exists=True))
@click.option("--metrics", multiple=True)
@click.option("--output", type=click.Path())
def calculate_metrics(dataset, metrics, output):
    """Calculate quality metrics for landmark data."""
    # Implementation using metrics_prototype2 patterns
    ...
```

### Phase 5: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [ ] API Reference (Sphinx)
- [ ] ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
- [ ] ä½¿ç”¨ä¾‹
- [ ] ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

---

## ğŸ“š å‚è€ƒè³‡æ–™

### è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- `pose_estimation_metrics_analysis.md` - ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­è¨ˆã®æ ¹æ‹ 
- `.github/copilot-instructions.md` - å®Ÿè£…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
- `guides/CODING_STYLE_GUIDE.md` - ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„

### å­¦è¡“æ–‡çŒ®

1. Liu & Yuan, "Recognizing Human Actions as the Evolution of Pose Estimation Maps", CVPR 2018
2. Cao et al., "OpenPose: Realtime Multi-Person 2D Pose Estimation", CVPR 2017
3. Mehta et al., "VNect: Real-time 3D Human Pose Estimation", ACM TOG 2017

---

## ğŸ” v2ã®è¨­è¨ˆåˆ¤æ–­ã¾ã¨ã‚

### âœ… æ¡ç”¨ã—ãŸè¨­è¨ˆ

| åˆ¤æ–­ | ç†ç”± |
|------|------|
| `SLDataset.from_zarr()` ä½¿ç”¨ | æ—¢å­˜ã®ã‚¤ãƒ³ãƒ•ãƒ©æ´»ç”¨ã€ã‚³ãƒ¼ãƒ‰å‰Šæ¸› |
| `utils.py` åˆ†é›¢ | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å›ºæœ‰ãƒ­ã‚¸ãƒƒã‚¯ã®æ˜ç¢ºåŒ– |
| zarr.Arrayå‚ç…§æ´»ç”¨ | é…å»¶èª­ã¿è¾¼ã¿ã®æ¨™æº–ãƒ‘ã‚¿ãƒ¼ãƒ³ |
| ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ãƒ™ãƒ«pyrightæŠ‘åˆ¶ | å‹•çš„å‹æ¨è«–ã®æ­£å½“ãªåˆ¶é™ |

### âŒ æ¡ç”¨ã—ãªã‹ã£ãŸè¨­è¨ˆ

| åˆ¤æ–­ | ç†ç”± |
|------|------|
| `IterableSLDataset` ä½œæˆ | æ—¢å­˜ã®é…å»¶èª­ã¿è¾¼ã¿ã§ååˆ† |
| `as_numpy()` ãƒ¡ã‚½ãƒƒãƒ‰ | æ‹¡å¼µæ©Ÿèƒ½ã§å¯¾å¿œã™ã¹ã |
| `sldataset.utils` ã¸ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£è¿½åŠ  | è²¬ä»»åˆ†é›¢ã®åŸå‰‡ |
| ã‚«ã‚¹ã‚¿ãƒ å‹ã‚¨ã‚¤ãƒªã‚¢ã‚¹ | `DefaultSLDatasetItem` ã§ååˆ† |

---

## ğŸ“ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### v2.0 ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—å®Œäº†åŸºæº–

- [x] SLDatasetçµ±åˆ
- [x] Phase 1ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…ï¼ˆNaNç‡ï¼‰
- [x] Phase 2ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…ï¼ˆæ™‚é–“çš„ä¸€è²«æ€§ï¼‰
- [x] Phase 3ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…ï¼ˆéª¨æ ¼åˆ¶ç´„ï¼‰
- [x] ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆutils.pyï¼‰
- [x] ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆCLIï¼‰
- [x] ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰æº–æ‹ ï¼ˆBlack, Flake8, Pyrightï¼‰
- [x] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ

### v2.1 ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†åŸºæº–

- [x] importlib.metadataçµ±åˆ
- [x] MetricCalculatorãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…
- [x] Metric â†’ LandmarkMetricéšå±¤åŒ–
- [x] `to_numpy_landmarks()` å‰Šé™¤ï¼ˆ`np.asarray()` æ¨å¥¨ï¼‰
- [x] `categorize_landmarks()` rsplitå®Ÿè£…
- [x] zarråˆ¤å®šã‚’ `.zgroup`/`.zarray` ãƒã‚§ãƒƒã‚¯ã«å¤‰æ›´
- [x] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ï¼ˆv2.1å¯¾å¿œï¼‰

### æœ¬ç•ªçµ±åˆæº–å‚™

- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- [ ] å¤–éƒ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®å‹•ä½œç¢ºèª
- [ ] CLIçµ±åˆï¼ˆ`sldataset2 metrics` ã‚³ãƒãƒ³ãƒ‰ï¼‰
- [ ] API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆSphinxï¼‰

---

## ğŸ”„ å¤‰æ›´å±¥æ­´

### v2.1 (2025-12-02)

**ä¸»è¦å¤‰æ›´**:
- importlib.metadata Entry Pointsçµ±åˆ
- MetricCalculatorãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ 
- Metric â†’ LandmarkMetric 2å±¤éšå±¤
- `to_numpy_landmarks()` å‰Šé™¤ã€`np.asarray()` + `__array__` æ¨å¥¨
- `categorize_landmarks()` ã‚’ rsplit(".", 1)[-1] å®Ÿè£…ã«å¤‰æ›´
- zarråˆ¤å®šã‚’ `.zgroup`/`.zarray` å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã«å¤‰æ›´

**ç ´å£Šçš„å¤‰æ›´**:
- `register_metric()` é–¢æ•°å‰Šé™¤
- `to_numpy_landmarks()` å‰Šé™¤
- ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¯ `LandmarkMetric` ã‚’ç¶™æ‰¿

**ç§»è¡Œã‚¬ã‚¤ãƒ‰**:
```python
# v2.0
from metrics_prototype2 import register_metric, create_metric
from metrics_prototype2.utils import to_numpy_landmarks

register_metric("completeness.nan_rate", NaNRateMetric, {})
metric = create_metric("completeness.nan_rate")
landmarks_np = to_numpy_landmarks(item.landmarks)

# v2.1
from metrics_prototype2 import MetricCalculator
import numpy as np

calculator = MetricCalculator()
calculator.add_metric("completeness.nan_rate")
landmarks_np = {k: np.asarray(v) for k, v in item.landmarks.items()}
results = calculator.calculate(landmarks_np["mediapipe.pose"])
```

### v2.0 (2025-11-27)

- åˆç‰ˆãƒªãƒªãƒ¼ã‚¹
- SLDatasetçµ±åˆ
- Phase 1-3ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£…

---

**æœ€çµ‚æ›´æ–°**: 2025å¹´12æœˆ2æ—¥  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: v2.1 ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†ã€æœ¬ç•ªçµ±åˆå¾…ã¡
